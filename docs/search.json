[
  {
    "objectID": "data/sfs/Kathmandu/Kathmandu.html",
    "href": "data/sfs/Kathmandu/Kathmandu.html",
    "title": "MUSA 550",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  All_Merged_Districts_Ward_Wi2  ENG dataset\n\nAll_Merged_Districts_Ward_Wi2\n\n                 0 0     false"
  },
  {
    "objectID": "data/sfs/Bhaktapur/Bhaktapur.html",
    "href": "data/sfs/Bhaktapur/Bhaktapur.html",
    "title": "MUSA 550",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  All_Merged_Districts_Ward_Wi2  ENG dataset\n\nAll_Merged_Districts_Ward_Wi2\n\n                 0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Unpacking Urban Data in Kathmandu",
    "section": "",
    "text": "This is the project website.\n\n\n\n\n\n\nImportant\n\n\n\nThis is going to be where my analysis is.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Unpacking Urban Data in Kathmandu",
    "section": "",
    "text": "This is the project website.\n\n\n\n\n\n\nImportant\n\n\n\nThis is going to be where my analysis is.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "analysis/2-static-images.html",
    "href": "analysis/2-static-images.html",
    "title": "Showing static visualizations",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and demonstrates how to generate static visualizations with matplotlib, pandas, and seaborn.\nStart by importing the packages we need:\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nLoad the “Palmer penguins” dataset from week 2:\n# Load data on Palmer penguins\npenguins = pd.read_csv(\"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/penguins.csv\")\n# Show the first ten rows\npenguins.head(n=10)    \n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007",
    "crumbs": [
      "Analysis",
      "Showing static visualizations"
    ]
  },
  {
    "objectID": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "href": "analysis/2-static-images.html#a-simple-visualization-3-different-ways",
    "title": "Showing static visualizations",
    "section": "A simple visualization, 3 different ways",
    "text": "A simple visualization, 3 different ways\n\nI want to scatter flipper length vs. bill length, colored by the penguin species\n\n\nUsing matplotlib\n\n# Setup a dict to hold colors for each species\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Initialize the figure \"fig\" and axes \"ax\"\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Group the data frame by species and loop over each group\n# NOTE: \"group\" will be the dataframe holding the data for \"species\"\nfor species, group_df in penguins.groupby(\"species\"):\n\n    # Plot flipper length vs bill length for this group\n    # Note: we are adding this plot to the existing \"ax\" object\n    ax.scatter(\n        group_df[\"flipper_length_mm\"],\n        group_df[\"bill_length_mm\"],\n        marker=\"o\",\n        label=species,\n        color=color_map[species],\n        alpha=0.75,\n        zorder=10\n    )\n\n# Plotting is done...format the axes!\n\n## Add a legend to the axes\nax.legend(loc=\"best\")\n\n## Add x-axis and y-axis labels\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\n\n## Add the grid of lines\nax.grid(True);\n\n\n\n\n\n\n\n\n\n\nHow about in pandas?\nDataFrames have a built-in “plot” function that can make all of the basic type of matplotlib plots!\nFirst, we need to add a new “color” column specifying the color to use for each species type.\nUse the pd.replace() function: it use a dict to replace values in a DataFrame column.\n\n# Calculate a list of colors\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Map species name to color \npenguins[\"color\"] = penguins[\"species\"].replace(color_map)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\ncolor\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n#1f77b4\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n#1f77b4\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n#1f77b4\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n#1f77b4\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n#1f77b4\n\n\n\n\n\n\n\nNow plot!\n\n# Same as before: Start by initializing the figure and axes\nfig, myAxes = plt.subplots(figsize=(10, 6))\n\n# Scatter plot two columns, colored by third\n# Use the built-in pandas plot.scatter function\npenguins.plot.scatter(\n    x=\"flipper_length_mm\",\n    y=\"bill_length_mm\",\n    c=\"color\",\n    alpha=0.75,\n    ax=myAxes, # IMPORTANT: Make sure to plot on the axes object we created already!\n    zorder=10\n)\n\n# Format the axes finally\nmyAxes.set_xlabel(\"Flipper Length (mm)\")\nmyAxes.set_ylabel(\"Bill Length (mm)\")\nmyAxes.grid(True);\n\n\n\n\n\n\n\n\nNote: no easy way to get legend added to the plot in this case…\n\n\nSeaborn: statistical data visualization\nSeaborn is designed to plot two columns colored by a third column…\n\n# Initialize the figure and axes\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# style keywords as dict\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\nstyle = dict(palette=color_map, s=60, edgecolor=\"none\", alpha=0.75, zorder=10)\n\n# use the scatterplot() function\nsns.scatterplot(\n    x=\"flipper_length_mm\",  # the x column\n    y=\"bill_length_mm\",  # the y column\n    hue=\"species\",  # the third dimension (color)\n    data=penguins,  # pass in the data\n    ax=ax,  # plot on the axes object we made\n    **style  # add our style keywords\n)\n\n# Format with matplotlib commands\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\nax.grid(True)\nax.legend(loc=\"best\");",
    "crumbs": [
      "Analysis",
      "Showing static visualizations"
    ]
  },
  {
    "objectID": "analysis/1-income_distribution.html",
    "href": "analysis/1-income_distribution.html",
    "title": "Understanding Kathmandu’s Wealth: Visualizing Census Data",
    "section": "",
    "text": "Statistically speaking, Nepal is a poor country. It ranks 180/222 in terms of GDP per capita 1, ranking well behind other post-conflict nations of Kosovo(132) and Laos (153). 76.2% of the adult population is literate 2 and 41.9% of households sleep under roofs of galvanized tin sheets 3.\nAlmost 42% of the Nation’s populations lives in housing made out of galvanized steel. Source: 2021 Nepal Census\nHowever, such reality seems extremely far away in the capital city of Kathmandu where Teslas frequent the roads. Kathmandu’s prosperity isn’t new and stems from a list of historic and geographic factors. Situated at 4.6K ft above sea level, the Kathmandu valley is a large swath of fertile flatland in Himalayan Range where steep topography made agriculture very difficult4. Due to this geographic advantange, the region has been continously settled for at least 2000 years 5. The large settlements attracted more people and soon Kathmandu found itself as an important trading hub, linking the India-Tibet land route 6. Kings built roads, waterworks, and schools; merchants traded gold, spices and silk; while pilgrims spread art, region and philosophy. Consequentialy, Kathmandu and its residents grew rich while its surrounding countryside languished into subsistence farming.\nWe can see Kathmandu’s regional dominance displayed clearly in its 2021 Census data7. A comprehensive decinnial survey, the 2021 census is the most recent and most representative data on Nepal’s socioeconomic factors. Key metrics such as number of households and their associated wealth quintile is present at the municipal ward level in excel format. While the data is not spatial, it is possible to use data cleaning methods to convert them. This report hence marks the first spatial exploration of the Nepal census data.\n\nWrangling The Data\nTo begin my analysis, I first load the ward level shapefiles for Kathmandu valley into my environment. No public GIS data exists on political boundaries—however, in its absence, civillians have taken up charge on digitizing hence. All spatial files in this analysis is thanks to the hard work of Kiran Joshi, whose blog can be found here.\nWhat is coloquially known as “Kathmandu” is in reality three cities. Legend says that three sons divided their father’s kingdom into three parts to rule equally, creating the three cities of Kathmandu, Lalitpur, and Bhaktapur. But in spirit and in function, these cities work as one. Hence, my analysis will start by calling and combining the three shapefiles.\n\nimport geopandas as gpd\nimport pandas as pd\n\nktm = gpd.read_file('../data/sfs/Kathmandu/Kathmandu.shp')\nbkt = gpd.read_file('../data/sfs/Bhaktapur/Bhaktapur.shp')\nltp = gpd.read_file('../data/sfs/Lalitpur/Lalitpur.shp')\n\ncities = pd.concat([ktm, bkt, ltp])\n\n#cleaning up the center columnm as it contains neighbourhood name information\ncities['Center'] = cities['Center'].str.replace(' Office$', '', regex=True)\n\ncities.head()\n\n\n\n\n\n\n\n\nOBJECTID\nState\nState_Code\nDistrict\nProtected\nMun_Name\nMun_Type\nCenter\nArea_SQKM\nWard_No\ngeometry\n\n\n\n\n0\n3707\nBagmati\n3\nKATHMANDU\nNaN\nGokarneshwor\nNagarpalika\nGokarneshwor Municipality\n7.0128\n3\nPOLYGON ((342664.728 3073511.945, 342660.154 3...\n\n\n1\n3708\nBagmati\n3\nKATHMANDU\nNaN\nGokarneshwor\nNagarpalika\nGokarneshwor Municipality\n4.6919\n4\nPOLYGON ((342803.560 3069107.750, 342787.801 3...\n\n\n2\n3709\nBagmati\n3\nKATHMANDU\nNaN\nGokarneshwor\nNagarpalika\nGokarneshwor Municipality\n1.0760\n5\nPOLYGON ((340158.801 3066905.027, 340126.624 3...\n\n\n3\n3710\nBagmati\n3\nKATHMANDU\nNaN\nGokarneshwor\nNagarpalika\nGokarneshwor Municipality\n0.5591\n6\nPOLYGON ((340531.184 3067725.024, 340535.003 3...\n\n\n4\n3711\nBagmati\n3\nKATHMANDU\nNaN\nGokarneshwor\nNagarpalika\nGokarneshwor Municipality\n1.3092\n8\nPOLYGON ((340879.585 3068658.365, 340889.756 3...\n\n\n\n\n\n\n\nNext, I call and clean the Household Income dataset. After a bit of manipulation and cleaning, my final dataframe gives me ward level information on the total number of households, and the number of households that fall under each wealth quintile ranging from 1 to 5 with 1 being the most economically vulnerable households.\n\nhhwealth = pd.read_excel('../data/census/HHwealth.xlsx')\n\n#creating new names for income quartiles\ncolnnames = [\n    'prov', 'dist', 'gapa', 'name', 'ward', 'tot_hh',\n    'quart1_count', 'quart2_count', 'quart3_count', 'quart4_count', 'quart5_count',\n    'quart1_%', 'quart2_%', 'quart3_%', 'quart4_%', 'quart5_%'\n]\n\n#dropping unnecesary values\nhhwealth = hhwealth.iloc[3:].reset_index(drop=True)\nhhwealth.columns = colnnames\n\n#dataset contains random text values interrupting wards, hence removing such rows\nnumeric_columns = [col for col in hhwealth.columns if col != 'name']\nfor col in numeric_columns:\n    hhwealth[col] = pd.to_numeric(hhwealth[col], errors='coerce')\n\n#only selecting the observations for the three municipal districts\nvalhhwealth = hhwealth[hhwealth['dist'].isin([28, 29, 30])]\n\nvalhhwealth.head()\n\n\n\n\n\n\n\n\nprov\ndist\ngapa\nname\nward\ntot_hh\nquart1_count\nquart2_count\nquart3_count\nquart4_count\nquart5_count\nquart1_%\nquart2_%\nquart3_%\nquart4_%\nquart5_%\n\n\n\n\n453\n3\n28\n0\nKathmandu\nNaN\n542892\n2038\n11398\n39406\n175348\n314702\n0.38\n2.10\n7.26\n32.30\n57.97\n\n\n454\n3\n28\n1\nShankharapur Municipality\nNaN\n7140\n376\n874\n1676\n2129\n2085\n5.27\n12.24\n23.47\n29.82\n29.20\n\n\n455\n3\n28\n1\nShankharapur Municipality\n1.0\n867\n83\n106\n334\n255\n89\n9.57\n12.23\n38.52\n29.41\n10.27\n\n\n456\n3\n28\n1\nShankharapur Municipality\n2.0\n426\n65\n98\n161\n69\n33\n15.26\n23.00\n37.79\n16.20\n7.75\n\n\n457\n3\n28\n1\nShankharapur Municipality\n3.0\n589\n36\n92\n156\n174\n131\n6.11\n15.62\n26.49\n29.54\n22.24\n\n\n\n\n\n\n\nAs there are no spatial geometries present in the municipal data, we would want to join the census infomation to our ward-level map by the name of the municipality and their corresponding ward. But, having been phonetically converted to English, they are not spelled the same way across the dataset. Additionally, the data also contains unnecesary (and unstandardized) descriptors such as “Municipality”, “Nagarpalika” which will inhibit a join.\nTo address these issues, I remove all unneeded suffixes and match my datasets using a fuzzy criteria. Two neighbourhoods are considered the same if their names are up to 80% similar.\n\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process\n\n#helper function to clean names\ndef clean_name(name):\n    name = name.strip()\n    suffs = [\n        ' Municipality',\n        ' Metropolitian City', \n        ' Metropolitan City',\n        ' Mahanagarpalika',\n        ' Nagarpalika',\n        ' Nagarpalika VDC',\n        ' Mun',\n        ' Gabisa Karyalaya',\n        ' Gabisa Bhawan',\n        ' Gaunpalika',\n        ' Sub Metro'\n    ]\n    clean = name\n    for suffix in suffs:\n        if clean.endswith(suffix):\n            clean = clean[:-len(suffix)].strip()\n    \n    return clean\n\n# Cleaning the column containing municipality information\ncities['Municipality'] = cities['Mun_Name'].apply(clean_name)\nvalhhwealth['Municipality'] = valhhwealth['name'].apply(clean_name)\n\n# fuzzy matching accoridng to cleaned names\ndef find_match(name, choices, min_score=80):\n    best_match = process.extractOne(name, choices)\n    if best_match and best_match[1] &gt;= min_score:\n        return best_match[0]\n    return None\n\n# creating a mapping column of fuzzy matched names\nname_mapping = {}\nfor name in cities['Municipality'].unique():\n    match = find_match(name, valhhwealth['Municipality'].unique())\n    if match:\n        name_mapping[name] = match\n\n#adding those to the dataset\ncities['new_name'] = cities['Municipality'].map(name_mapping)\n\n# joining my census data to the spatial files\ncities_inc = pd.merge(cities, \n                     valhhwealth,\n                     left_on=['new_name', 'Ward_No'],\n                     right_on=['Municipality', 'ward'],\n                     how='left')\n\n#finally, converting my data to WGS84\ncities_inc = cities_inc.to_crs('EPSG:4326')\n\n/var/folders/mm/m098rbs1529c7x072qh31ncw0000gn/T/ipykernel_96790/2053149582.py:29: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  valhhwealth['Municipality'] = valhhwealth['name'].apply(clean_name)\n\n\nWe can see Kathmandu’s settlement patterns immediately by plotting the spread of houses. Here, wards near the center of the city have significantly higher number of households than wards comprising the surorunding hills. The large variance in values presents problem with scaling the data. Hence, to address this issue, we would need to decide our city limits.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, ax = plt.subplots(figsize=(15, 10))\nax.set_facecolor('ivory')\n\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Futura']\n\nplot = cities_inc.plot(ax=ax, \n    column='tot_hh',\n    cmap='BuPu',\n    edgecolor='black',\n    linewidth=0.5,\n    legend=True,\n    legend_kwds={'label': 'Total Households'}\n)\n\nax.set_title(\"Kathmandu's Population Concentrated at the Center\", \n    size=18, \n    pad=20\n)\nax.set_axis_off()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\nSetting Limits for Kathmandu\nOur analysis will not be very useful if we include sparsely populated hill wards in our dataset. Our study area needs to have tigher city limits—for this purpose I use a road density based selection criteria. Using road network data from Open Street Maps, I calculate the density of streets by area for each ward. I then filter out all wards who fall in the bottom 30th percentile for road density.\n\nimport osmnx as ox\nvalley = cities_inc.dissolve().make_valid()\nstreet_network = ox.graph_from_polygon(valley.geometry.iloc[0], network_type=\"drive\")\nox.plot_graph(ox.project_graph(street_network), node_size = 0)\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/predicates.py:798: RuntimeWarning:\n\ninvalid value encountered in intersects\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/set_operations.py:340: RuntimeWarning:\n\ninvalid value encountered in union\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/predicates.py:798: RuntimeWarning:\n\ninvalid value encountered in intersects\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/set_operations.py:340: RuntimeWarning:\n\ninvalid value encountered in union\n\n\n\n\n\n\n\n\n\n\nThe street network map also paints a similar picture—high density of roads near the center before dissapearing in the surrounding hills.\n\nfrom shapely.geometry import Polygon\n\n#getting street edges\nedges = ox.graph_to_gdfs(street_network, edges = True, nodes = False).to_crs(cities_inc.crs)\n\n#counting number of streets per ward\ncities_inc['streetcount'] = cities_inc.geometry.apply(\n    lambda x: len(edges[edges.intersects(x)])  \n)\n\n#creating density metric\ncities_inc['streetdensity'] = cities_inc['streetcount']/cities_inc['Area_SQKM']\n\n#selecting 30th quartile threshold\nthreshold = cities_inc['streetdensity'].quantile(0.30)\n\n#subsetting values\nmain_city = cities_inc[cities_inc['streetdensity'] &gt;= threshold]\n\nThe resulting map shows a much tighter city limits though the issues with scale still presists.\n\nfig, ax = plt.subplots(figsize=(15, 10))\nax.set_facecolor('ivory')\n\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Futura']\n\nplot = main_city.plot(ax=ax, \n    column='tot_hh',\n    cmap='BuPu',\n    edgecolor='black',\n    linewidth=0.5,\n    legend=True,\n    legend_kwds={'label': 'Total Households'}\n)\n\nax.set_title(\"Kathmandu's Population Concentrated at the Center\", \n    size=18, \n    pad=20\n)\nax.set_axis_off()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\nLogging our total number of households gives us a better picture. Here, we see conspicous pockets of empty space surrounded by a growing belt of dense settlements. There are three empty cores—each corresponding to the historic city centers of Kathmandu, Lalitpur, and Bhaktapur. While many variations exist, this does match the “donut-shape” typology of city settlement.\n\nfrom shapely.geometry import Point\n#  Creating a gdf of historic city center area\ncenters = gpd.GeoDataFrame(\n    {\n        'name': ['Kathmandu', 'Patan', 'Bhaktapur'],\n        'geometry': [\n            Point(85.30727341768024, 27.705040937390145),\n            Point(85.32530690762836, 27.672831546274733),\n            Point(85.42829510275436, 27.672202975996818)\n        ]\n    },\n    crs='EPSG:4326'\n)\n\nfig, ax = plt.subplots(figsize=(15, 10))\nax.set_facecolor('ivory')\n\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Futura']\n\nmain_city['log_hh'] = np.log(main_city['tot_hh'])\n\nmain_city.plot(ax=ax, \n    column='log_hh',\n    cmap='BuPu',\n    edgecolor='black',\n    linewidth=0.5,\n    legend=True,\n    legend_kwds={'label': 'Density of Households'}\n)\n\ncenters.plot(ax=ax,\n           color=\"gold\",\n           edgecolor='darkmagenta',\n           alpha=0.3,\n           markersize=500)  # Increase dot size\n\nfor idx, row in centers.iterrows():\n   ax.annotate(row['name'], \n               xy=(row.geometry.x, row.geometry.y),\n               color='darkmagenta',\n               bbox=dict(\n                  facecolor='bisque',\n                  edgecolor='darkmagenta',\n                  alpha=0.7,\n                  pad=2\n                  ),\n               alpha=0.7,\n               xytext=(5, 5), \n               textcoords='offset points')\n\nax.set_title(\"Empty Urban Core Surrounded by Dense Belt\", \n    size=18, \n    pad=20\n)\nax.set_axis_off()\n\nplt.tight_layout()\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/geopandas/geodataframe.py:1538: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\n\n\nExploring Wealth Quatintiles in the City\nHow does the population distribution transform to wealth quantiles? To understand this, I created a folium map where the percentage of households in Lowest and Highest Income Quartiles is shown over a map of Kathmandu. This map visually corresponds to how I understand wealth in the city:\n\nRichest Areas are in South part of the city (corresponding to areas with a lot of INGO offices), and distant suburban hills.\nAreas near the core have some of the lowest incidence of high income households in the city.\nDistribution of lowest quantiles doesn’t tell us much as most residents of Kathmandu are fall under the richer quantiles compared to the rest of Nepal. However, we do notice that presence of households in the lowest quantile increases rapidly once we enter the hills in the western parrt of the city.\n\n\nimport folium\nm = main_city.explore(\n    column='quart5_%',\n    legend=True,\n    cmap='viridis',\n    name='Highest Income',\n    tooltip=['name', 'ward', 'quart5_%', 'quart4_%', 'quart3_%', 'quart2_%','quart1_%']\n)\nmain_city.explore(\n    column='quart1_%',\n    cmap='inferno',\n    name='Lowest Income',\n    m=m ,\n    tooltip=['name', 'ward', 'quart5_%', 'quart4_%', 'quart3_%', 'quart2_%','quart1_%']\n)\n\nfolium.LayerControl().add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nWe can explore the distribution of households belonging to different quartiles below. Following our initial assumptions about the relative prosperty of Kathmandu, the city center only starts showing a higher concentration of households starting from quartile 3, the middle income quartile.\n\nimport hvplot.pandas\nimport holoviews as hv\nfrom holoviews import opts\nhv.extension('bokeh')\n\nplot1 = main_city.melt(\n    id_vars=[\"OBJECTID\", \"geometry\"],\n    value_vars=['quart5_%', 'quart4_%', 'quart3_%', 'quart2_%','quart1_%'],\n    var_name=\"Quintile\",\n    value_name=\"Percentage\"\n)\n\n\nplot1.hvplot(geo=True, \n             c='Percentage', \n             alpha=0.45, \n             groupby='Quintile',\n             widget_location='left_top',\n             color_key='viridis',\n             tiles='OSM',\n             tiles_opts={'alpha': 0.5})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n  \n\n\n\n\n\n\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning:\n\ninvalid value encountered in intersection\n\nWARNING:param.main: tiles_opts option not found for polygons plot with bokeh; similar options include: ['tiles']\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n\n\n\n\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n/opt/homebrew/Caskroom/mambaforge/base/envs/musa-550-fall-2023/lib/python3.10/site-packages/shapely/constructive.py:181: RuntimeWarning:\n\ninvalid value encountered in buffer\n\n\n\n\n\nEstimating Median Income\nThough the census data doesn’t provide us with information on median household income, it is possible to estimate this data using other publicly available government data. The National Statistics Office has information on the median and mean income values for each quartile available on their website. Using the median income value for each quartile, we estimated the median income for each ward depending on their composition of households.\n\nplot2 = main_city.copy()\n\nmed_inc = {\n    'quart1': 242797,  \n    'quart2': 299341,  \n    'quart3': 377000,\n    'quart4': 465301,  \n    'quart5': 617882  \n}\n\nplot2['Est Income'] = (\n    plot2['quart1_count'] * med_inc['quart1'] +\n    plot2['quart2_count'] * med_inc['quart2'] +\n    plot2['quart3_count'] * med_inc['quart3'] +\n    plot2['quart4_count'] * med_inc['quart4'] +\n    plot2['quart5_count'] * med_inc['quart5']\n) / plot2[['quart1_count', 'quart5_count', 'quart3_count', \n        'quart4_count', 'quart5_count']].sum(axis=1)\n\n\nplot2['Est Income'] = pd.to_numeric((plot2['Est Income'])/100000).round(1)\n\nWe then plot our distribution. Here, income is given in 100k Nepali Rupees per year. The data shows two rings of high income wards in the city.\n\nimport altair as alt\n\nalt.Chart(plot2).mark_geoshape(\n    stroke='white',\n    strokeWidth=0.5\n).encode(\n    color=alt.Color('Est Income:Q', \n        scale=alt.Scale(scheme='viridis'),\n        title='Annual Income (Lakhs NRP)'),\n    tooltip=['Mun_Name:N', 'ward:N','Est Income:Q']\n).properties(\n    width=800,\n    height=600,\n    title='Two Rings of High Income Settlements in the City'\n)\n\n\n\n\n\n\n\n\n\nMapping Kathmandu’s Poverty\nKathmandu is a mixed-income city where the rich live alongside (sometimes as stay-in landlords of) the poor. However, this does’t mean that every ward in the city is made up of the same composition of households. I am interested in learning more about the spatial distribution of low-income households.\nHowever, the information provided by the census doesn’t help much in the context of Kathmandu. As living costs in the city are so much higher than rest of the country, a person in the middle quartile elsewhere may find themselves being nominally low income. Hence to account for such dynamics, we combine the lowest 3 quartiles to make a single, “Low Income” catagory of the city.\n\nplot3 = main_city.copy()\nplot3['Low Income'] = plot3[['quart1_%', 'quart2_%', 'quart3_%']].sum(axis=1)\n\nfig, ax = plt.subplots(figsize=(15, 10), facecolor='antiquewhite')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Futura']\n\nplot3.plot(ax=ax, column='Low Income', \n          cmap='RdPu',\n          edgecolor='darkseagreen',\n          linewidth=0.5,\n          legend=True,\n          legend_kwds={'label': '% of Households in Low Income Quartile',\n                      'orientation': 'vertical'}) \n\n\n\ncenters.plot(ax=ax,\n           color=\"gold\",\n           edgecolor='darkmagenta',\n           alpha=0.3,\n           markersize=500) \n\nfor idx, row in centers.iterrows():\n   ax.annotate(row['name'], \n               xy=(row.geometry.x, row.geometry.y),\n               color='darkmagenta',\n               bbox=dict(\n                  facecolor='bisque',\n                  edgecolor='darkmagenta',\n                  alpha=0.7,\n                  pad=2\n                  ),\n               alpha=0.7,\n               xytext=(15, 5), \n               textcoords='offset points')\n\nax.set_title(\"Concentration of Poverty in Historic Cores\", \n    size=18, \n    pad=20\n)\nax.set_axis_off()",
    "crumbs": [
      "Analysis",
      "Understanding Kathmandu's Wealth: Visualizing Census Data"
    ]
  },
  {
    "objectID": "analysis/3-altair-hvplot.html",
    "href": "analysis/3-altair-hvplot.html",
    "title": "Altair and Hvplot Charts",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive charts produced using Altair and hvPlot.",
    "crumbs": [
      "Analysis",
      "Altair and Hvplot Charts"
    ]
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in Altair",
    "text": "Example: Measles Incidence in Altair\nFirst, let’s load the data for measles incidence in wide format:\n\n\nCode\nurl = \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/measles_incidence.csv\"\ndata = pd.read_csv(url, skiprows=2, na_values=\"-\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nWEEK\nALABAMA\nALASKA\nARIZONA\nARKANSAS\nCALIFORNIA\nCOLORADO\nCONNECTICUT\nDELAWARE\n...\nSOUTH DAKOTA\nTENNESSEE\nTEXAS\nUTAH\nVERMONT\nVIRGINIA\nWASHINGTON\nWEST VIRGINIA\nWISCONSIN\nWYOMING\n\n\n\n\n0\n1928\n1\n3.67\nNaN\n1.90\n4.11\n1.38\n8.38\n4.50\n8.58\n...\n5.69\n22.03\n1.18\n0.4\n0.28\nNaN\n14.83\n3.36\n1.54\n0.91\n\n\n1\n1928\n2\n6.25\nNaN\n6.40\n9.91\n1.80\n6.02\n9.00\n7.30\n...\n6.57\n16.96\n0.63\nNaN\n0.56\nNaN\n17.34\n4.19\n0.96\nNaN\n\n\n2\n1928\n3\n7.95\nNaN\n4.50\n11.15\n1.31\n2.86\n8.81\n15.88\n...\n2.04\n24.66\n0.62\n0.2\n1.12\nNaN\n15.67\n4.19\n4.79\n1.36\n\n\n3\n1928\n4\n12.58\nNaN\n1.90\n13.75\n1.87\n13.71\n10.40\n4.29\n...\n2.19\n18.86\n0.37\n0.2\n6.70\nNaN\n12.77\n4.66\n1.64\n3.64\n\n\n4\n1928\n5\n8.03\nNaN\n0.47\n20.79\n2.38\n5.13\n16.80\n5.58\n...\n3.94\n20.05\n1.57\n0.4\n6.70\nNaN\n18.83\n7.37\n2.91\n0.91\n\n\n\n\n5 rows × 53 columns\n\n\n\nThen, use the pandas.melt() function to convert it to tidy format:\n\n\nCode\nannual = data.drop(\"WEEK\", axis=1)\nmeasles = annual.groupby(\"YEAR\").sum().reset_index()\nmeasles = measles.melt(id_vars=\"YEAR\", var_name=\"state\", value_name=\"incidence\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nstate\nincidence\n\n\n\n\n0\n1928\nALABAMA\n334.99\n\n\n1\n1929\nALABAMA\n111.93\n\n\n2\n1930\nALABAMA\n157.00\n\n\n3\n1931\nALABAMA\n337.29\n\n\n4\n1932\nALABAMA\n10.21\n\n\n\n\n\n\n\nFinally, load altair:\n\nimport altair as alt\n\nAnd generate our final data viz:\n\n# use a custom color map\ncolormap = alt.Scale(\n    domain=[0, 100, 200, 300, 1000, 3000],\n    range=[\n        \"#F0F8FF\",\n        \"cornflowerblue\",\n        \"mediumseagreen\",\n        \"#FFEE00\",\n        \"darkorange\",\n        \"firebrick\",\n    ],\n    type=\"sqrt\",\n)\n\n# Vertical line for vaccination year\nthreshold = pd.DataFrame([{\"threshold\": 1963}])\n\n# plot YEAR vs state, colored by incidence\nchart = (\n    alt.Chart(measles)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"YEAR:O\", axis=alt.Axis(title=None, ticks=False)),\n        y=alt.Y(\"state:N\", axis=alt.Axis(title=None, ticks=False)),\n        color=alt.Color(\"incidence:Q\", sort=\"ascending\", scale=colormap, legend=None),\n        tooltip=[\"state\", \"YEAR\", \"incidence\"],\n    )\n    .properties(width=650, height=500)\n)\n\nrule = alt.Chart(threshold).mark_rule(strokeWidth=4).encode(x=\"threshold:O\")\n\nout = chart + rule\nout",
    "crumbs": [
      "Analysis",
      "Altair and Hvplot Charts"
    ]
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in hvplot",
    "text": "Example: Measles Incidence in hvplot\n\n\n\n\n\n\n\n\n\n\n\nGenerate the same data viz in hvplot:\n\n# Make the heatmap with hvplot\nheatmap = measles.hvplot.heatmap(\n    x=\"YEAR\",\n    y=\"state\",\n    C=\"incidence\", # color each square by the incidence\n    reduce_function=np.sum, # sum the incidence for each state/year\n    frame_height=450,\n    frame_width=600,\n    flip_yaxis=True,\n    rot=90,\n    colorbar=False,\n    cmap=\"viridis\",\n    xlabel=\"\",\n    ylabel=\"\",\n)\n\n# Some additional formatting using holoviews \n# For more info: http://holoviews.org/user_guide/Customizing_Plots.html\nheatmap = heatmap.redim(state=\"State\", YEAR=\"Year\")\nheatmap = heatmap.opts(fontsize={\"xticks\": 0, \"yticks\": 6}, toolbar=\"above\")\nheatmap",
    "crumbs": [
      "Analysis",
      "Altair and Hvplot Charts"
    ]
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes examples of technical analysis done using Jupyter notebooks. Each sub-section highlights different types of analyses and visualizations. In particular, it highlights that we can easily publish interactive visualizations produced with packages such as hvPlot, altair, or Folium, without losing any of the interactive features.\nOn this page, you might want to share more introductory or background information about the analyses to help guide the reader.",
    "crumbs": [
      "Analysis"
    ]
  },
  {
    "objectID": "analysis/4-folium.html",
    "href": "analysis/4-folium.html",
    "title": "Interactive Maps with Folium",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive maps produced using Folium.",
    "crumbs": [
      "Analysis",
      "Interactive Maps with Folium"
    ]
  },
  {
    "objectID": "analysis/4-folium.html#finding-the-shortest-route",
    "href": "analysis/4-folium.html#finding-the-shortest-route",
    "title": "Interactive Maps with Folium",
    "section": "Finding the shortest route",
    "text": "Finding the shortest route\nThis example finds the shortest route between the Art Musuem and the Liberty Bell using osmnx.\n\nimport osmnx as ox\n\nFirst, identify the lat/lng coordinates for our places of interest. Use osmnx to download the geometries for the Libery Bell and Art Museum.\n\nphilly_tourism = ox.features_from_place(\"Philadelphia, PA\", tags={\"tourism\": True})\n\n\nart_museum = philly_tourism.query(\"name == 'Philadelphia Museum of Art'\").squeeze()\n\nart_museum.geometry\n\n\n\n\n\n\n\n\n\nliberty_bell = philly_tourism.query(\"name == 'Liberty Bell'\").squeeze()\n\nliberty_bell.geometry\n\n\n\n\n\n\n\n\nNow, extract the lat and lng coordinates\nFor the Art Museum geometry, we can use the .geometry.centroid attribute to calculate the centroid of the building footprint.\n\nliberty_bell_x = liberty_bell.geometry.x\nliberty_bell_y = liberty_bell.geometry.y\n\n\nart_museum_x = art_museum.geometry.centroid.x\nart_museum_y = art_museum.geometry.centroid.y\n\nNext, use osmnx to download the street graph around Center City.\n\nG_cc = ox.graph_from_address(\n    \"City Hall, Philadelphia, USA\", dist=1500, network_type=\"drive\"\n)\n\nNext, identify the nodes in the graph closest to our points of interest.\n\n# Get the origin node (Liberty Bell)\norig_node = ox.nearest_nodes(G_cc, liberty_bell_x, liberty_bell_y)\n\n# Get the destination node (Art Musuem)\ndest_node = ox.nearest_nodes(G_cc, art_museum_x, art_museum_y)\n\nFind the shortest path, based on the distance of the edges:\n\n# Get the shortest path --&gt; just a list of node IDs\nroute = ox.shortest_path(G_cc, orig_node, dest_node, weight=\"length\")\n\nHow about an interactive version?\nosmnx has a helper function ox.utils_graph.route_to_gdf() to convert a route to a GeoDataFrame of edges.\n\nox.utils_graph.route_to_gdf(G_cc, route, weight=\"length\").explore(\n    tiles=\"cartodb positron\",\n    color=\"red\",\n)\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Analysis",
      "Interactive Maps with Folium"
    ]
  },
  {
    "objectID": "analysis/4-folium.html#examining-trash-related-311-requests",
    "href": "analysis/4-folium.html#examining-trash-related-311-requests",
    "title": "Interactive Maps with Folium",
    "section": "Examining Trash-Related 311 Requests",
    "text": "Examining Trash-Related 311 Requests\nFirst, let’s load the dataset from a CSV file and convert to a GeoDataFrame:\n\n\nCode\n# Load the data from a CSV file into a pandas DataFrame\ntrash_requests_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/trash_311_requests_2020.csv\"\n)\n\n# Remove rows with missing geometry\ntrash_requests_df = trash_requests_df.dropna(subset=[\"lat\", \"lon\"])\n\n\n# Create our GeoDataFrame with geometry column created from lon/lat\ntrash_requests = gpd.GeoDataFrame(\n    trash_requests_df,\n    geometry=gpd.points_from_xy(trash_requests_df[\"lon\"], trash_requests_df[\"lat\"]),\n    crs=\"EPSG:4326\",\n)\n\n\nLoad neighborhoods and do the spatial join to associate a neighborhood with each ticket:\n\n\nCode\n# Load the neighborhoods\nneighborhoods = gpd.read_file(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/zillow_neighborhoods.geojson\"\n)\n\n# Do the spatial join to add the \"ZillowName\" column\nrequests_with_hood = gpd.sjoin(\n    trash_requests,\n    neighborhoods.to_crs(trash_requests.crs),\n    predicate=\"within\",\n)\n\n\nLet’s explore the 311 requests in the Greenwich neighborhood of the city:\n\n# Extract out the point tickets for Greenwich\ngreenwich_tickets = requests_with_hood.query(\"ZillowName == 'Greenwich'\")\n\n\n# Get the neighborhood boundary for Greenwich\ngreenwich_geo = neighborhoods.query(\"ZillowName == 'Greenwich'\")\n\ngreenwich_geo.squeeze().geometry\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto has callout blocks that you can use to emphasize content in different ways. This is a “Note” callout block. More info is available on the Quarto documentation.\n\n\nImport the packages we need:\n\nimport folium\nimport xyzservices\n\nCombine the tickets as markers and the neighborhood boundary on the same Folium map:\n\n# Plot the neighborhood boundary\nm = greenwich_geo.explore(\n    style_kwds={\"weight\": 4, \"color\": \"black\", \"fillColor\": \"none\"},\n    name=\"Neighborhood boundary\",\n    tiles=xyzservices.providers.CartoDB.Voyager,\n)\n\n\n# Add the individual tickets as circle markers and style them\ngreenwich_tickets.explore(\n    m=m,  # Add to the existing map!\n    marker_kwds={\"radius\": 7, \"fill\": True, \"color\": \"crimson\"},\n    marker_type=\"circle_marker\", # or 'marker' or 'circle'\n    name=\"Tickets\",\n)\n\n# Hse folium to add layer control\nfolium.LayerControl().add_to(m)\n\nm  # show map\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Analysis",
      "Interactive Maps with Folium"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hello everyone\n\n\nOn this about page, you might want to add more information about yourself, the project, or course.\n\n\nMy name is Avani Adhikari, a student for this python class. Here is a picture from my favourite game, Hollow Knight.\nYou can find more information about me on my personal website.\nThis site is an example site showing how to use Quarto for the final project for MUSA 550, during fall 2024.\nWrite something about you\n\nor about something you like",
    "crumbs": [
      "About Me"
    ]
  },
  {
    "objectID": "data/sfs/Lalitpur/Lalitpur.html",
    "href": "data/sfs/Lalitpur/Lalitpur.html",
    "title": "MUSA 550",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  All_Merged_Districts_Ward_Wi2  ENG dataset\n\nAll_Merged_Districts_Ward_Wi2\n\n                 0 0     false"
  }
]